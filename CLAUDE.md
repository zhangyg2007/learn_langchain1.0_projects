# CLAUDE.md - LangChain 1.0 ä¸­å›½AIæ¨¡å‹ä¸ä¼ä¸šå·¥ä½œæµå¼€å‘æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå…¨é¢å‡çº§çš„ä¼ä¸šçº§LangChainå­¦ä¹ å¹³å°ï¼Œä¸“æ³¨äºä¸­å›½ä¸»æµå¤§æ¨¡å‹ï¼ˆDeepSeekã€æ™ºè°±GLMã€æœˆä¹‹æš—é¢Kimiã€é€šä¹‰åƒé—®ç­‰ï¼‰å’ŒAIå·¥ä½œæµå·¥å…·ï¼ˆDifyã€RAGFlowã€n8nã€LangFlowï¼‰çš„æ·±åº¦é›†æˆã€‚

**æ ¸å¿ƒç‰¹è‰²:**
- ğŸ§  **ä¸­å›½å¤§æ¨¡å‹å…¨å®¶æ¡¶**: 15+ä¸ªä¸­å›½å’Œå›½é™…ä¸»æµæ¨¡å‹æ”¯æŒ
- ğŸš€ **AIå·¥ä½œæµæ·±åº¦é›†æˆ**: Difyã€RAGFlowã€n8nã€Flowiseç­‰å¹³å°é›†æˆ
- ğŸ¯ **ç»Ÿä¸€å¤šæ¨¡å‹æ¶æ„**: å•é…ç½®ç®¡ç†ã€åŠ¨æ€æ¨¡å‹åˆ‡æ¢ã€æ™ºèƒ½æ•…éšœè½¬ç§»
- ğŸ­ **ç”Ÿäº§çº§éƒ¨ç½²**: Docker/K8sæ”¯æŒã€ä¼ä¸šçº§APIã€å®Œæ•´ç›‘æ§è¿ç»´

## ğŸ¯ æ ¸å¿ƒä»»åŠ¡ç±»åˆ«

### 1. ğŸ”° åŸºç¡€å­¦ä¹ ä»»åŠ¡ (L1 Foundation)
**ç›®æ ‡**: LangChainç”Ÿæ€ç­‘åŸº + ç®€å•Agentå¼€å‘
**å‘¨æœŸ**: 6å‘¨
**ä¸»è¦ä»»åŠ¡ç±»å‹**: ç¯å¢ƒé…ç½®ã€é“¾å¼ç¼–ç¨‹ã€Agentsæ¦‚å¿µã€RAGåŸºç¡€

### 2. ğŸ“ˆ è¿›é˜¶å­¦ä¹ ä»»åŠ¡ (L2 Intermediate)  
**ç›®æ ‡**: ä¸­å›½å¤§æ¨¡å‹å®æˆ˜ + å¤æ‚åä½œç³»ç»Ÿ
**å‘¨æœŸ**: 4å‘¨
**ä¸»è¦ä»»åŠ¡ç±»å‹**: DeepSeeké•¿æ–‡æœ¬ã€æ™ºè°±GLMæ•°å­¦æ¨ç†ã€å¤šAgentååŒ

### 3. ğŸ­ é«˜çº§å­¦ä¹ ä»»åŠ¡ (L3 Advanced)
**ç›®æ ‡**: AIå·¥ä½œæµé›†æˆ + ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²  
**å‘¨æœŸ**: 4å‘¨
**ä¸»è¦ä»»åŠ¡ç±»å‹**: Difyä½ä»£ç ã€RAGFlowä¼ä¸šçº§RAGã€APIæ¶æ„è®¾è®¡

### 4. ğŸ† ä¸“å®¶çº§ä»»åŠ¡ (L4 Specialization)
**ç›®æ ‡**: æŒ‰åœºæ™¯çš„çºµæ·±å­¦ä¹  + ä¼ä¸šä¸“é¡¹è®­ç»ƒ
**å‘¨æœŸ**: çµæ´»å®‰æ’
**ä¸»è¦ä»»åŠ¡ç±»å‹**: è¡Œä¸šå®šåˆ¶ã€ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆ

## ğŸ›  æŠ€æœ¯æ ˆä¸ä¾èµ–ç®¡ç†

### ä¸­å›½å¤§æ¨¡å‹ä¾èµ–
```python
# requirements-chinese-models.txt
deepseek-api>=0.3.0        # æ·±åº¦æ±‚ç´¢
tongyi>=0.3.0              # é€šä¹‰åƒé—®  
zhipuai>=2.0.0             # æ™ºè°±GLM
moonshot>=1.0              # æœˆä¹‹æš—é¢Kimi
baichuan>=1.0              # ç™¾å·æ™ºèƒ½
dashscope>=1.0             # é˜¿é‡Œçµç§¯
```

### AIå·¥ä½œæµå·¥å…·ä¾èµ–
```python
# requirements-workflow-tools.txt
dify-client>=0.1.0         # Dify APIå®¢æˆ·ç«¯
ragflow-client>=0.1.0      # RAGFlowå®¢æˆ·ç«¯  
flowise>=1.4.0             # Flowiseä½ä»£ç å¹³å°
n8n-nodes>=0.1.0           # n8nå·¥ä½œæµèŠ‚ç‚¹
jina>=3.23.0               # ç¥ç»æœç´¢æ¡†æ¶
haystack-ai>=2.0.0         # Haystackå·¥ä½œæµ
```

### å‘é‡æ•°æ®åº“ä¼˜åŒ–
```python
# requirements-vector-stores.txt
milvus-client>=2.3.0       # æ˜Ÿç¯Milvus (ä¸­å›½ä¼˜åŒ–)
qdrant-client>=1.7.0       # Qdranté«˜æ€§èƒ½
weaviate-client>=3.25.0    # Weaviateæ”¯æŒä¸­æ–‡
chroma-client>=0.4.0       # ChromaDBä¸­æ–‡æ”¯æŒç‰ˆ
pgvector>=0.2.0            # PostgreSQLå‘é‡æ’ä»¶
```

## ğŸ”§ é…ç½®ç®¡ç†

### ç¯å¢ƒé…ç½®æ¨¡æ¿
```bash
# .env.chinese-models.example
# æ·±åº¦æ±‚ç´¢ DeepSeek ğŸš€
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat

# æ™ºè°±GLM ğŸ§   
ZHIPU_API_KEY=your_zhipu_api_key_here
ZHIPU_MODEL=glm-4

# æœˆä¹‹æš—é¢Kimi ğŸŒ™
MOONSHOT_API_KEY=your_moonshot_api_key_here
MOONSHOT_MODEL=moonshot-v1-8k

# AIå·¥ä½œæµå·¥å…·é…ç½®
DIFY_API_KEY=your_dify_api_key_here
DIFY_BASE_URL=http://localhost:3000/api/v1

RAGFLOW_API_KEY=your_ragflow_api_key_here  
RAGFLOW_BASE_URL=http://localhost:9380/api/v1
```

## ğŸš€ æ¨¡å‹é€‚é…å™¨å®ç°

### ç»Ÿä¸€æ¨¡å‹ç®¡ç†
```python
# config/model_adapters.py
class UnifiedModelManager:
    """ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨ - æ”¯æŒå¤šæ¨¡å‹åŠ¨æ€åˆ‡æ¢"""
    
    def __init__(self):
        self.models = {}
        self.active_model = None
        self.fallback_chain = []
    
    def register_model(self, provider: str, model_config: dict):
        """æ³¨å†Œæ–°çš„æ¨¡å‹æä¾›å•†"""
        adapter = self._create_adapter(provider, model_config)
        self.models[provider] = adapter
    
    def get_chat_model(self, provider: str = None):
        """è·å–èŠå¤©æ¨¡å‹ - æ”¯æŒæ™ºèƒ½æ•…éšœè½¬ç§»"""
        if provider and provider in self.models:
            try:
                return self.models[provider]
            except Exception as e:
                logger.warning(f"Primary model {provider} failed: {e}")
                return self._try_fallback()
        
        return self.models.get(self.active_model) or self._try_fallback()
    
    def switch_model(self, provider: str):
        """åŠ¨æ€åˆ‡æ¢æ¨¡å‹ - æ— éœ€é‡å¯"""
        if provider in self.models:
            self.active_model = provider
            logger.info(f"Switched to {provider} model")
        else:
            raise ValueError(f"Unknown provider: {provider}")
```

### ä¸­å›½æ¨¡å‹ç‰¹æ®Šé€‚é…
```python
# config/chinese_models_adapters.py
class DeepSeekAdapter(BaseModelAdapter):
    """æ·±åº¦æ±‚ç´¢æ¨¡å‹é€‚é…å™¨"""
    
    def __init__(self, api_key: str, model: str = "deepseek-chat"):
        self.client = DeepSeekClient(api_key=api_key)
        self.model = model
    
    def invoke(self, prompt: str, **kwargs): # ä¸­æ–‡é•¿æ–‡æœ¬ä¼˜åŒ–
        enhanced_prompt = self._add_chinese_context(prompt)
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": enhanced_prompt}],
            **kwargs
        )
        return response.choices[0].message.content
    
    def _add_chinese_context(self, prompt: str) -> str:
        """æ·»åŠ ä¸­æ–‡è¯­å¢ƒä¼˜åŒ–"""
        return f"è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š{prompt}"

class ZhipuGLMAdapter(BaseModelAdapter):
    """æ™ºè°±GLMé€‚é…å™¨ - æ•°å­¦æ¨ç†å¢å¼º"""
    
    def __init__(self, api_key: str, model: str = "glm-4"):
        self.client = ZhipuAI(api_key=api_key)
        self.model = model
    
    def invoke(self, prompt: str, **kwargs):
        # æ•°å­¦æ¨ç†ç‰¹æ®Šå¤„ç†
        if self._is_math_problem(prompt):
            prompt = self._enhance_math_prompt(prompt)
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            **kwargs
        )
        return response.choices[0].message.content
```

## ğŸ¯ AIå·¥ä½œæµé›†æˆ

### Difyé›†æˆå®ç°
```python
# config/dify_integration.py
class DifyIntegration:
    """Difyä½ä»£ç AIåº”ç”¨å¹³å°é›†æˆ"""
    
    def __init__(self, api_key: str, base_url: str):
        self.client = DifyClient(api_key=api_key, base_url=base_url)
    
    def create_chat_chain(self, name: str, config: dict) -> str:
        """åˆ›å»ºèŠå¤©åº”ç”¨é“¾"""
        app_config = {
            "name": name,
            "mode": "chat",
            "model_config": {
                "provider": "openai",
                "model": "gpt-3.5-turbo",
                "temperature": 0.7
            },
            "prompt_template": config.get("prompt_template", ""),
            "tools": config.get("tools", [])
        }
        
        app = self.client.applications.create(app_config)
        return app.id
    
    def chat_with_knowledge(self, query: str, user_id: str, app_id: str) -> dict:
        """åŸºäºçŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”"""
        response = self.client.chat.messages.create(
            app_id=app_id,
            inputs={"query": query},
            query=query,
            user=user_id,
            response_mode="streaming"
        )
        return response
```

### RAGFlowä¼ä¸šçº§RAGé›†æˆ
```python
# config/ragflow_integration.py
class RAGFlowIntegration:
    """RAGFlowä¼ä¸šçº§RAGè§£å†³æ–¹æ¡ˆé›†æˆ"""
    
    def __init__(self, api_key: str, base_url: str):
        self.client = RAGFlowClient(api_key=api_key, base_url=base_url)
    
    def create_knowledge_base(self, name: str, description: str = ""):
        """åˆ›å»ºä¼ä¸šçŸ¥è¯†åº“"""
        kb_config = {
            "name": name,
            "description": description,
            "embedding_model": "text-embedding-ada-002",
            "language": "chinese",  # ä¸­æ–‡ä¼˜åŒ–
            "chunk_size": 800,
            "chunk_overlap": 80
        }
        
        knowledge_base = self.client.knowledge_bases.create(kb_config)
        return knowledge_base.id
    
    def add_documents(self, kb_id: str, documents: List[Document], **kwargs):
        """æ‰¹é‡æ·»åŠ æ–‡æ¡£ - æ”¯æŒä¸­æ–‡åˆ†è¯ä¼˜åŒ–"""
        # ä¸­æ–‡æ–‡æ¡£ç‰¹æ®Šå¤„ç†
        processed_docs = []
        for doc in documents:
            enhanced_doc = self._enhance_chinese_document(doc)
            processed_docs.append(enhanced_doc)
        
        # åˆ†æ‰¹æ¬¡ä¸Šä¼ 
        batch_size = kwargs.get('batch_size', 50)
        for i in range(0, len(processed_docs), batch_size):
            batch = processed_docs[i:i + batch_size]
            self.client.documents.upload(kb_id, batch)
    
    def smart_qa_chain(self, question: str, kb_id: str) -> dict:
        """æ™ºèƒ½é—®ç­”é“¾ - è‡ªåŠ¨ä¸­æ–‡ä¼˜åŒ–"""
        # ä¸­æ–‡é—®é¢˜å¢å¼º
        enhanced_question = self._enhance_chinese_question(question)
        
        response = self.client.retrieval.search(
            kb_id=kb_id,
            query=enhanced_question,
            top_k=5,
            rerank=True,
            rerank_model="chinese-reranker"  # ä¸­æ–‡é‡æ’åºæ¨¡å‹
        )
        
        # ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_chinese_answer(
            question=enhanced_question, 
            retrieved_contexts=response.results
        )
        
        return {
            "question": question,
            "answer": answer,
            "sources": [r.source for r in response.results],
            "confidence": response.confidence
        }
```

## ğŸ§ª å¼€å‘å·¥ä½œæµä¸æµ‹è¯•

### å¿«é€Ÿå¼€å‘è„šæœ¬
```python
# scripts/quick_dev.py
"""å¿«é€Ÿå¼€å‘è°ƒè¯•è„šæœ¬"""

def quick_model_test():
    """å¿«é€Ÿæµ‹è¯•å¤šæ¨¡å‹é€‚é…"""
    from config import UnifiedModelManager, get_chat_model
    
    # æµ‹è¯•ä¸­å›½æ¨¡å‹
    models_to_test = ["deepseek", "zhipu", "moonshot", "qwen"]
    
    for model_name in models_to_test:
        try:
            model = get_chat_model(model_name)
            response = model.invoke("è¯·ä»‹ç»ä¸€ä¸‹LangChain")
            print(f"âœ… {model_name}: {response[:100]}...")
        except Exception as e:
            print(f"âŒ {model_name} failed: {e}")

def quick_workflow_test():
    """å¿«é€Ÿæµ‹è¯•å·¥ä½œæµé›†æˆ"""
    from config import DifyIntegration, RAGFlowIntegration
    
    # æµ‹è¯•Difyé›†æˆ
    dify = DifyIntegration()
    try:
        app_id = dify.create_chat_chain("æµ‹è¯•åº”ç”¨", {})
        print(f"âœ… Dify app created: {app_id}")
    except Exception as e:
        print(f"âŒ Dify failed: {e}")
    
    # æµ‹è¯•RAGFlowé›†æˆ
    ragflow = RAGFlowIntegration()
    try:
        kb_id = ragflow.create_knowledge_base("æµ‹è¯•çŸ¥è¯†åº“")
        print(f"âœ… RAGFlow KB created: {kb_id}")
    except Exception as e:
        print(f"âŒ RAGFlow failed: {e}")

if __name__ == "__main__":
    print("ğŸš€ ä¸­å›½AIæ¨¡å‹ä¸ä¼ä¸šå·¥ä½œæµå¿«é€Ÿæµ‹è¯•")
    quick_model_test()
    quick_workflow_test()
```

### æµ‹è¯•æœ€ä½³å®è·µ
```python
# tests/test_model_adapters.py
import pytest
from config import UnifiedModelManager, get_chat_model

class TestChineseModels:
    """ä¸­å›½æ¨¡å‹é€‚é…å™¨æµ‹è¯•"""
    
    @pytest.mark.parametrize("provider", ["deepseek", "zhipu", "moonshot"])
    def test_chinese_model_basic(self, provider):
        """æµ‹è¯•åŸºæœ¬ä¸­æ–‡å¯¹è¯èƒ½åŠ›"""
        model = get_chat_model(provider)
        response = model.invoke("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸‹ä½ è‡ªå·±")
        
        assert response is not None
        assert len(response) > 0
        assert any(word in response for word in ["ä½ å¥½", "æˆ‘æ˜¯", "LangChain"])
    
    def test_model_fallback_chain(self):
        """æµ‹è¯•æ¨¡å‹æ•…éšœè½¬ç§»é“¾"""
        manager = UnifiedModelManager()
        
        # æ¨¡æ‹Ÿä¸»è¦æ¨¡å‹å¤±è´¥
        with patch.object(manager.models["deepseek"], "invoke", side_effect=Exception("API Error")):
            result = manager.get_chat_model("deepseek").invoke("æµ‹è¯•æ¶ˆæ¯")
            
            # åº”è¯¥å›é€€åˆ°å…¶ä»–æ¨¡å‹
            assert result is not None
            assert "fallback" in str(result).lower()

class TestWorkflowIntegration:
    """å·¥ä½œæµé›†æˆæµ‹è¯•"""
    
    def test_dify_app_creation(self):
        """æµ‹è¯•Difyåº”ç”¨åˆ›å»º"""
        from config import DifyIntegration
        
        dify = DifyIntegration(api_key="test_key", base_url="http://localhost:3000")
        
        with patch.object(dify.client.applications, 'create') as mock_create:
            mock_create.return_value = type('obj', (object,), {'id': 'test_app_id'})
            
            app_id = dify.create_chat_chain("æµ‹è¯•åº”ç”¨", {})
            assert app_id == "test_app_id"
```

## ğŸ­ ç”Ÿäº§éƒ¨ç½²æŒ‡å—

### DockeråŒ–éƒ¨ç½²
```yaml
# docker-compose.yml
version: '3.8'

services:
  langchain-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DEFAULT_PROVIDER=deepseek
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DIFY_API_KEY=${DIFY_API_KEY}
      - RAGFLOW_BASE_URL=http://ragflow:8000/api/v1
    depends_on:
      - ragflow
      - milvus
      - redis
    volumes:
      - ./app:/app
    
  ragflow:
    image: infiniflow/ragflow:v1.0
    ports:
      - "9380:9380"
    environment:
      - RAGFLOW_DB_HOST=postgres
    
  milvus:
    image: milvusdb/milvus:v2.3
    ports:
      - "19530:19530"
    volumes:
      - milvus_data:/var/lib/milvus
    
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_DB=langchain_db
      - POSTGRES_USER=langchain
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  milvus_data:
  postgres_data:
  redis_data:
```

### Kubernetesé›†ç¾¤éƒ¨ç½²
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langchain-chinese-models
  labels:
    app: langchain-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: langchain-app
  template:
    metadata:
      labels:
        app: langchain-app
    spec:
      containers:
      - name: langchain-app
        image: ghcr.io/zhangyg2007/learn_langchain1.0_projects:latest
        ports:
        - containerPort: 8000
        env:
        - name: DEFAULT_PROVIDER
          value: "deepseek"
        - name: DEEPSEEK_API_KEY
          valueFrom:
            secretKeyRef:
              name: langchain-secrets
              key: deepseek-api-key
        - name: DIFY_API_KEY
          valueFrom:
            secretKeyRef:
              name: langchain-secrets
              key: dify-api-key
        readinessProbe:
          httpGet:
            path: /api/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      imagePullSecrets:
      - name: github-container-registry
```

## ğŸ“Š æ€§èƒ½ç›‘æ§ä¸è¿ç»´

### ç›‘æ§æŒ‡æ ‡è®¾ç½®
```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# æ¨¡å‹è°ƒç”¨ç›¸å…³æŒ‡æ ‡
MODEL_REQUESTS = Counter(
    'model_requests_total',
    'Total model requests by provider and status',
    ['provider', 'model', 'status']
)

MODEL_RESPONSE_TIME = Histogram(
    'model_response_time_seconds',
    'Model response time in seconds',
    ['provider', 'model']
)

ACTIVE_MODEL_USAGE = Gauge(
    'active_model_usage',
    'Currently active model usage',
    ['provider', 'model']
)

class ModelMetrics:
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ç›‘æ§"""
    
    def track_model_call(self, provider: str, model: str):
        """è£…é¥°å™¨ï¼šè¿½è¸ªæ¨¡å‹è°ƒç”¨"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                status = "success"
                
                try:
                    result = func(*args, **kwargs)
                    return result
                except Exception as e:
                    status = "error"
                    raise
                finally:
                    duration = time.time() - start_time
                    MODEL_REQUESTS.labels(
                        provider=provider, 
                        model=model, 
                        status=status
                    ).inc()
                    MODEL_RESPONSE_TIME.labels(
                        provider=provider, 
                        model=model
                    ).observe(duration)
            
            return wrapper
        return decorator
```

## ğŸ›  å¸¸ç”¨å¼€å‘å‘½ä»¤

### ç¯å¢ƒé…ç½®
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-chinese-models.txt
pip install -r requirements-workflow-tools.txt
pip install -r requirements-vector-stores.txt

# ç¯å¢ƒå˜é‡é…ç½®
cp .env.chinese-models.example .env
# ç¼–è¾‘ .env æ–‡ä»¶å¡«å…¥APIå¯†é’¥
```

### æ¨¡å‹æµ‹è¯•
```bash
# å¿«é€Ÿæµ‹è¯•æ‰€æœ‰ä¸­å›½æ¨¡å‹
python scripts/quick_dev.py

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_model_adapters.py::TestChineseModels -v

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python scripts/benchmark_models.py

# RAGç³»ç»Ÿæµ‹è¯•
python scripts/test_rag_systems.py
```

### ç”Ÿäº§éƒ¨ç½²
```bash
# Dockeræ„å»º
docker build -t langchain-chinese-models .

# Docker Composeå¯åŠ¨
docker-compose up -d

# Kuberneteséƒ¨ç½²
kubectl apply -f k8s/

# ç›‘æ§æŸ¥çœ‹
kubectl get pods -l app=langchain-app
kubectl logs -l app=langchain-app -f
```

### ä»£ç è´¨é‡æ£€æŸ¥
```bash
# ä»£ç æ ¼å¼åŒ–
black .
isort .

# ç±»å‹æ£€æŸ¥
mypy .

# ä»£ç è´¨é‡
pylint config/

# å®‰å…¨æ‰«æ
bandit -r config/
```

## ğŸ¤– å­¦ä¹ è·¯å¾„å®æ–½

### Week 1-2: åŸºç¡€ç­‘åŸº
```bash
cd examples/01_basics/01_environment_setup/
jupyter lab 01_setup.ipynb
cd ../02_first_chain/
jupyter lab 01_hello_chain_quick.ipynb
```

### Week 3-4: Agentå¼€å‘
```bash
cd examples/03_agents/01_basic_agents/
jupyter lab basic_agents_overview.ipynb
cd ../02_tool_agents/
jupyter lab tool_integration_master.ipynb
```

### Week 5-6: RAGç³»ç»Ÿ
```bash
cd examples/04_rag/01_vector_stores/
jupyter lab chinese_rag_optimization.ipynb
cd ../02_document_loaders/
jupyter lab enterprise_document_processing.ipynb
```

### Week 7+: ä¼ä¸šçº§é›†æˆ
```bash
cd examples/enterprises/
jupyter lab dify_enterprise_integration.ipynb
jupyter lab ragflow_production_setup.ipynb
```

## ğŸ”„ CI/CD è‡ªåŠ¨åŒ–

### GitHub Actionså·¥ä½œæµ
```yaml
# .github/workflows/test-and-deploy.yml
name: ä¸­å›½AIæ¨¡å‹æµ‹è¯•ä¸éƒ¨ç½²

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10"]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run Chinese model tests
      env:
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        ZHIPU_API_KEY: ${{ secrets.ZHIPU_API_KEY }}
      run: |
        pytest tests/test_chinese_models.py -v --cov=.
    
    - name: Test workflow integrations
      run: |
        pytest tests/test_workflow_integration.py -v
    
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t langchain-chinese-models:${{ github.sha }} .
        docker tag langchain-chinese-models:${{ github.sha }} langchain-chinese-models:latest
    
    - name: Deploy to production
      run: |
        kubectl apply -f k8s/
        kubectl rollout status deployment/langchain-chinese-models
```

## ğŸ¯ æ•…éšœæ’æŸ¥æŒ‡å—

### å¸¸è§æ¨¡å‹APIé—®é¢˜
```python
# scripts/debug_model_api.py
class ModelAPIDebugger:
    """æ¨¡å‹APIæ•…éšœè¯Šæ–­å·¥å…·"""
    
    def diagnose_connection(self, provider: str):
        """è¯Šæ–­æ¨¡å‹è¿æ¥é—®é¢˜"""
        issues = []
        
        # 1. APIå¯†é’¥éªŒè¯
        if not self._validate_api_key(provider):
            issues.append(f"âŒ {provider}: APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
        
        # 2. ç½‘ç»œè¿é€šæ€§æ£€æŸ¥
        if not self._check_network_connectivity(provider):
            issues.append(f"âŒ {provider}: ç½‘ç»œè¿æ¥å¤±è´¥")
        
        # 3. æ¨¡å‹å¯ç”¨æ€§éªŒè¯
        if not self._check_model_availability(provider):
            issues.append(f"âŒ {provider}: æŒ‡å®šæ¨¡å‹ä¸å¯ç”¨")
        
        # 4. é¢åº¦æ£€æŸ¥
        usage = self._check_usage_limit(provider)
        if usage and usage['remaining'] < 1000:
            issues.append(f"âš ï¸ {provider}: APIé¢åº¦ä¸è¶³ï¼Œå‰©ä½™{usage['remaining']}æ¬¡")
        
        return issues
    
    def generate_diagnostic_report(self) -> dict:
        """ç”Ÿæˆå®Œæ•´è¯Šæ–­æŠ¥å‘Š"""
        providers = ["deepseek", "zhipu", "moonshot", "qwen", "baichuan"]
        report = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "healthy",
            "provider_status": {},
            "recommendations": []
        }
        
        for provider in providers:
            issues = self.diagnose_connection(provider)
            if issues:
                report["provider_status"][provider] = {
                    "status": "error",
                    "issues": issues
                }
                report["overall_status"] = "degraded"
            else:
                report["provider_status"][provider] = {
                    "status": "healthy",
                    "issues": []
                }
        
        # ç”Ÿæˆå»ºè®®
        if report["overall_status"] == "degraded":
            report["recommendations"] = [
                "æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç¯å¢ƒå˜é‡è®¾ç½®",
                "éªŒè¯ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®", 
                "è€ƒè™‘å¯ç”¨å¤‡ç”¨æ¨¡å‹æä¾›å•†",
                "æŸ¥çœ‹æ¨¡å‹æœåŠ¡çŠ¶æ€é¡µé¢äº†è§£å·²çŸ¥é—®é¢˜"
            ]
        
        return report
```

### ä¼ä¸šçº§æ”¯æŒé€šé“
```python
# support/enterprise_support.py
class EnterpriseSupportToolkit:
    """ä¼ä¸šæ”¯æŒå·¥å…·é›†"""
    
    def create_support_ticket(self, issue_data: dict) -> str:
        """åˆ›å»ºæ”¯æŒå·¥å•"""
        ticket_id = f"SUP-{int(time.time())}"
        
        ticket = {
            "id": ticket_id,
            "type": issue_data.get("type", "technical"),
            "priority": issue_data.get("priority", "medium"),
            "description": issue_data.get("description", ""),
            "environment": self._collect_environment_info(),
            "logs": self._collect_relevant_logs(issue_data),
            "created_at": datetime.now().isoformat(),
            "status": "open"
        }
        
        # ä¿å­˜å·¥å•
        self._save_ticket(ticket)
        
        # å‘é€é€šçŸ¥
        self._notify_support_team(ticket)
        
        return ticket_id
    
    def generate_health_check_endpoint(self) -> dict:
        """ç”Ÿæˆå¥åº·æ£€æŸ¥ç«¯ç‚¹å“åº”"""
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0",
            "models": self._check_all_model_status(),
            "workflows": self._check_workflow_status(),
            "dependencies": self._check_dependency_status(),
            "performance": self._get_performance_metrics()
        }
```

## ğŸ“š å­¦ä¹ èµ„æºä¸æœ€ä½³å®è·µ

### æ¨èå­¦ä¹ è·¯å¾„
1. **æ–°æ‰‹å…¥é—¨**: `examples/01_basics/` â†’ 6å‘¨åŸºç¡€è¯¾ç¨‹
2. **è¿›é˜¶å®æˆ˜**: `examples/02_intermediate/` â†’ ä¸­å›½å¤§æ¨¡å‹å®æˆ˜
3. **ä¼ä¸šåº”ç”¨**: `examples/03_advanced/` â†’ AIå·¥ä½œæµé›†æˆ
4. **ç”Ÿäº§éƒ¨ç½²**: `examples/04_deployment/` â†’ Docker/K8séƒ¨ç½²

### ä»£ç è§„èŒƒ
- âœ… ä½¿ç”¨ç±»å‹æ³¨è§£ (PEP 484)
- âœ… éµå¾ªPEP 8ç¼–ç è§„èŒƒ  
- âœ… å†™æ–‡æ¡£å­—ç¬¦ä¸² (Googleé£æ ¼)
- âœ… æ·»åŠ å•å…ƒæµ‹è¯• (pytest)
- âœ… å…³æ³¨å®‰å…¨æœ€ä½³å®è·µ (banditæ‰«æ)

### è´¡çŒ®æŒ‡å—
1. Forké¡¹ç›®åˆ°ä¸ªäººè´¦æˆ·
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯Pull Requestå¹¶æä¾›è¯¦ç»†è¯´æ˜

---

## ğŸ“ æ”¯æŒä¸è”ç³»

**é¡¹ç›®ç»´æŠ¤**: zhangyg2007  
**GitHub**: https://github.com/zhangyg2007/learn_langchain1.0_projects  
**ä¼ä¸šæ”¯æŒ**: æä¾›ä¼ä¸šçº§å®šåˆ¶å¼€å‘ä¸æŠ€æœ¯åŸ¹è®­æœåŠ¡

---

**ğŸ¯ æœ€ç»ˆç›®æ ‡**: é€šè¿‡æœ¬é¡¹ç›®ï¼Œæ‚¨å°†æŒæ¡ä»åŸºç¡€LangChainåº”ç”¨åˆ°ä¼ä¸šçº§ä¸­å›½AIå¤§æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œæˆä¸ºAIåŸç”Ÿåº”ç”¨å¼€å‘ä¸“å®¶ï¼

**å‡†å¤‡å¥½äº†å—ï¼Ÿç«‹åˆ»å¼€å§‹ä½ çš„ä¸­å›½AIå¤§æ¨¡å‹å¼€å‘ä¹‹æ—…ï¼** ğŸš€ğŸ‡¨ğŸ‡³âœ¨