#!/usr/bin/env python3
"""
LangChain L3 Advanced - Week 11  
è¯¾ç¨‹æ ‡é¢˜: ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡è®¾è®¡
å­¦ä¹ ç›®æ ‡:
  - æŒæ¡å¼‚æ­¥RAGæŸ¥è¯¢å¤„ç†æ¶æ„è®¾è®¡
  - å­¦ä¹ æµå¼å“åº”(Server-Sent Events)
  - å®æ–½ä¼ä¸šçº§è¿æ¥æ± ä¸å¹¶å‘ä¼˜åŒ–
  - å®ç°å‘é‡åº“å¼‚æ­¥æŸ¥è¯¢ä¼˜åŒ–
ä½œè€…: Claude Code æ•™å­¦å›¢é˜Ÿ
åˆ›å»ºæ—¶é—´: 2024-01-16
ç‰ˆæœ¬: 1.0.0
å…ˆå†³æ¡ä»¶: å®Œæˆ01_fastapi_enterprise_architecture.py
"""

import asyncio
import uuid
import json
import time
from typing import Dict, List, Optional, AsyncGenerator, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from datetime import datetime
import logging
from pathlib import Path

# å¼‚æ­¥FastAPIç»„ä»¶
try:
    from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
    from fastapi.responses import JSONResponse, StreamingResponse
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel, Field, validator
    print("âœ… FastAPIå¼‚æ­¥ç»„ä»¶å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ FastAPIå¼‚æ­¥ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    raise

# å¼‚æ­¥å­˜å‚¨ä¸AIç»„ä»¶
try:
    import aiohttp
    import aiofiles
    import redis.asyncio as redis
    print("âœ… å¼‚æ­¥å­˜å‚¨å®¢æˆ·ç«¯å¯¼å…¥æˆåŠŸ")
    async_storage_available = True
except ImportError as e:
    print(f"âš ï¸ å¼‚æ­¥å­˜å‚¨ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…: pip install aiofiles redis[hiredis]")
    async_storage_available = False

# å‘é‡æ•°æ®åº“å’ŒAIæ¨¡å‹
try:
    from qdrant_client import QdrantClient, models
    from qdrant_client.async_qdrant_client import AsyncQdrantClient
    print("âœ… Qdrantå‘é‡æ•°æ®åº“å¯¼å…¥æˆåŠŸ")
    vector_db_available = True
except ImportError as e:
    print(f"âš ï¸ å‘é‡æ•°æ®åº“å¯¼å…¥å¤±è´¥: {e}")
    vector_db_available = False

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AsyncRAGConfig:
    """å¼‚æ­¥RAGé…ç½®"""
    max_concurrent_queries: int = 10
    query_timeout_seconds: int = 30
    retry_attempts: int = 3
    retry_delay_seconds: float = 0.5
    batch_size: int = 5
    max_sources: int = 5
    min_confidence: float = 0.7

@dataclass
class RAGQuery:
    """RAGæŸ¥è¯¢æ¨¡å‹"""
    query: str = Field(..., min_length=1, max_length=2000)
    domain: str = Field(default="general", description="æŸ¥è¯¢é¢†åŸŸåˆ†ç±»")
    context: Optional[List[str]] = Field(default=None, description="å†å²ä¸Šä¸‹æ–‡")
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int = Field(default=1500, ge=1, le=8192)
    top_k: int = Field(default=10, ge=1, le=50)
    similarity_threshold: float = Field(default=0.7, ge=0.0, le=1.0)
    return_sources: bool = Field(default=True)

@dataclass 
class RAGResponse:
    """RAGå“åº”æ¨¡å‹"""
    query: str
    answer: str
    sources: List[Dict[str, Any]] = field(default_factory=list)
    confidence: float = 0.0
    processing_time: float = 0.0
    retrieval_time: float = 0.0
    generation_time: float = 0.0
    used_provider: str = ""
    request_id: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    chunks: List[Dict[str, Any]] = field(default_factory=list)
    scores: List[float] = field(default_factory=list) 
    reranked_results: List[Dict[str, Any]] = field(default_factory=list)
    retrieval_time: float = 0.0

class EnterpriseAsyncRAGService:
    """ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡"""
    
    def __init__(self, config: AsyncRAGConfig = None):
        self.config = config or AsyncRAGConfig()
        self.request_semaphore = asyncio.Semaphore(self.config.max_concurrent_queries)
        self.cache_client = None
        self.vector_store = None
        self.query_history = []
        self.performance_stats = {"total_queries": 0, "avg_response_time": 0.0}
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        
    def _initialize_components(self):
        """åˆå§‹åŒ–å¼‚æ­¥ç»„ä»¶"""
        logger.info("ğŸš€ åˆå§‹åŒ–ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡ç»„ä»¶")
        
        # åˆå§‹åŒ–ç¼“å­˜
        if async_storage_available:
            try:
                self.cache_client = redis.from_url("redis://localhost:6379/0")
                logger.info("âœ… Rediså¼‚æ­¥ç¼“å­˜åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ Redisç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        if vector_db_available:
            try:
                self.vector_store = AsyncQdrantClient(":memory:")  # æ¼”ç¤ºç”¨å†…å­˜å­˜å‚¨
                logger.info("âœ… Qdrantå‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ Qdrantå‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.info("âœ… ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    async def process_query_async(self, query_data: RAGQuery) -> RAGResponse:
        """å¼‚æ­¥å¤„ç†RAGæŸ¥è¯¢"""
        request_id = str(uuid.uuid4())
        start_time = time.time()
        logger.info(f"[RID:{request_id}] å¼€å§‹å¼‚æ­¥å¤„ç†RAGæŸ¥è¯¢") 
        
        async with self.request_semaphore:
            try:
                # 1. æŸ¥è¯¢é¢„å¤„ç†å’Œæ ‡å‡†åŒ–
                preprocessed_query = await self._preprocess_query(query_data.query)
                await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿé¢„å¤„ç†å»¶è¿Ÿ
                
                # 2. æ£€æŸ¥ç¼“å­˜
                cached_response = await self._check_cache(preprocessed_query)
                if cached_response:
                    logger.info(f"[RID:{request_id}] ç¼“å­˜å‘½ä¸­ï¼Œå¿«é€Ÿå“åº”")
                    return cached_response
                
                # 3. å¹¶è¡Œå¤„ç†æ£€ç´¢å’Œæ„å›¾åˆ†æ
                retrieval_task = asyncio.create_task(
                    self._async_retrieval(preprocessed_query, query_data.top_k, query_data.similarity_threshold)
                )
                intent_task = asyncio.create_task(
                    self._async_intent_analysis(query_data.query)
                )
                
                # ç­‰å¾…æ£€ç´¢ç»“æœ
                retrieval_result = await retrieval_task
                generation_params = await intent_task
                
                # 4. å¼‚æ­¥ç”Ÿæˆå›ç­”
                final_answer = await self._async_generate_answer(
                    query_data.query, 
                    retrieval_result, 
                    generation_params,
                    query_data.temperature,
                    query_data.max_tokens
                )
                
                # 5. æ„å»ºå“åº”
                total_time = time.time() - start_time
                
                response = RAGResponse(
                    query=query_data.query,
                    answer=final_answer["answer"],
                    sources=final_answer["sources"],
                    confidence=final_answer["confidence"],
                    processing_time=total_time,
                    retrieval_time=retrieval_result.retrieval_time,
                    generation_time=final_answer["generation_time"],
                    used_provider=final_answer.get("provider", "enterprise"),
                    request_id=request_id,
                    timestamp=datetime.now(),
                    metadata=final_answer.get("metadata", {})
                )
                
                # 6. å¼‚æ­¥æŒä¹…åŒ–å’Œç¼“å­˜
                await asyncio.gather(
                    self._cache_response(preprocessed_query, response),
                    self._log_query_async(query_data, response)
                )
                
                # 7. æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                await self._update_performance_stats(total_time)
                
                logger.info(f"[RID:{request_id}] å¼‚æ­¥RAGæŸ¥è¯¢å¤„ç†å®Œæˆï¼Œæ€»ç”¨æ—¶: {total_time:.3f}s")
                return response
                
            except asyncio.TimeoutError:
                logger.error(f"[RID:{request_id}] æŸ¥è¯¢è¶…æ—¶")
                return self._handle_timeout_error(query_data.query, request_id)
            except Exception as e:
                logger.error(f"[RID:{request_id}] æŸ¥è¯¢å¤„ç†é”™è¯¯: {str(e)}")
                return await self._handle_processing_error(query_data.query, str(e), request_id)
            finally:
                logger.info(f"[RID:{request_id}] è¯·æ±‚å¤„ç†ç»“æŸ")
    
    async def stream_query_async(self, query_data: RAGQuery) -> AsyncGenerator[str, None]:
        """å¼‚æ­¥æµå¼æŸ¥è¯¢å¤„ç†"""
        request_id = str(uuid.uuid4())
        start_time = time.time()
        
        logger.info(f"[RID:{request_id}] å¼€å§‹å¼‚æ­¥æµå¼æŸ¥è¯¢å¤„ç†")
        
        try:
            # å‘é€å¼€å§‹ä¿¡å·
            yield f"event: start\ndata: {{\"request_id\": \"{request_id}\", \"timestamp\": \"{datetime.now().isoformat()}\"}}\n\n"
            await asyncio.sleep(0.1)
            
            # 1. æŸ¥è¯¢é¢„å¤„ç†é˜¶æ®µ
            yield f"event: preprocessing\ndata: {{\"status\": \"Query preprocessing in progress\", \"step\": 1}}\n\n"
            preprocessed_query = await self._preprocess_query(query_data.query)
            await asyncio.sleep(0.2)
            
            # 2. æ„å›¾åˆ†æé˜¶æ®µ
            yield f"event: intent_analysis\ndata: {{\"status\": \"Analyzing user intent\", \"step\": 2}}\n\n"
            intent_analysis = await self._async_intent_analysis(query_data.query)
            await asyncio.sleep(0.3)
            
            # 3. æ–‡æ¡£æ£€ç´¢é˜¶æ®µ
            yield f"event: document_retrieval\ndata: {{\"status\": \"Retrieving relevant documents\", \"step\": 3}}\n\n"
            retrieval_start = time.time()
            
            # å¼‚æ­¥æ£€ç´¢ - åˆ†æ®µå‘é€è¿›åº¦
            async for progress in self._stream_retrieval_progress(preprocessed_query, query_data.top_k):
                yield f"event: retrieval_progress\ndata: {json.dumps(progress)}\n\n"
            
            retrieval_result = await self._async_retrieval(preprocessed_query, query_data.top_k, query_data.similarity_threshold)
            retrieval_time = time.time() - retrieval_start
            
            yield f"event: retrieval_complete\ndata: {{\"status\": \"Document retrieval complete\", \"retrieval_time\": {retrieval_time:.2f}}}\n\n"
            
            # 4. ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
            yield f"event: answer_generation\ndata: {{\"status\": \"Generating intelligent response\", \"step\": 4}}\n\n"
            
            # æµå¼ç”Ÿæˆç­”æ¡ˆ
            final_answer = ""
            async for chunk in self._stream_generate_answer(
                query_data.query, retrieval_result, intent_analysis
            ):
                final_answer += chunk["text"]
                yield f"event: answer_chunk\ndata: {json.dumps(chunk)}\n\n"
            
            # 5. å®Œæˆé˜¶æ®µ
            total_time = time.time() - start_time
            completion_data = {
                "final_answer": final_answer,
                "processing_complete": True,
                "total_time_seconds": total_time,
                "sources_count": len(retrieval_result.chunks),
                "confidence_score": final_answer.count("é‡è¦") * 0.01 + 0.7
            }
            
            yield f"event: completion\ndata: {json.dumps(completion_data)}\n\n"
            await asyncio.sleep(0.1)
            
            # å¼‚æ­¥è®°å½•æ—¥å¿—
            asyncio.create_task(self._log_stream_query_async(query_data, final_answer, total_time, request_id))
            
            logger.info(f"[RID:{request_id}] æµå¼æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œæ€»ç”¨æ—¶: {total_time:.3f}s")
            
        except Exception as e:
            logger.error(f"[RID:{request_id}] æµå¼æŸ¥è¯¢å¤„ç†é”™è¯¯: {str(e)}")
            yield f"event: error\ndata: {{\"error\": \"{str(e)}\", \"request_id\": \"{request_id}\"}}\n\n"
        finally:
            yield "event: end\ndata: {}\n\n"
    
    async def _preprocess_query(self, query: str) -> str:
        """å¼‚æ­¥æŸ¥è¯¢é¢„å¤„ç†"""
        # æ¨¡æ‹Ÿå¼‚æ­¥é¢„å¤„ç†
        await asyncio.sleep(0.01)
        
        # ä¸­æ–‡ä¼˜åŒ–å¤„ç†
        processed_query = query.strip()
        if any(word in query for word in ['ä¸­å›½', 'ä¸­æ–‡', 'å¤§æ¨¡å‹']):
            processed_query = f"ä¸­æ–‡ä¼˜åŒ–çš„æŸ¥è¯¢: {processed_query}"
        
        return processed_query
    
    async def _check_cache(self, query: str) -> Optional[RAGResponse]:
        """æ£€æŸ¥å¼‚æ­¥ç¼“å­˜"""
        if not self.cache_client:
            return None
        
        try:
            cache_key = f"rag_response:{hash(query)}"
            cached_data = await self.cache_client.get(cache_key)
            
            if cached_data:
                cached_dict = json.loads(cached_data)
                return RAGResponse(**cached_dict)
            
        except Exception as e:
            logger.warning(f"ç¼“å­˜æ£€æŸ¥å¤±è´¥: {e}")
        
        return None
    
    async def _cache_response(self, query: str, response: RAGResponse) -> None:
        """å¼‚æ­¥ç¼“å­˜å“åº”"""
        if not self.cache_client:
            return
        
        try:
            cache_key = f"rag_response:{hash(query)}"
            cache_data = {
                key: value.isoformat() if isinstance(value, datetime) else value
                for key, value in response.__dict__.items()
            }
            
            await self.cache_client.setex(
                cache_key,
                timedelta(minutes=15),
                json.dumps(cache_data)
            )
            
        except Exception as e:
            logger.warning(f"ç¼“å­˜å“åº”å¤±è´¥: {e}")
    
    async def _async_retrieval(self, query: str, top_k: int, similarity_threshold: float) -> RetrievalResult:
        """å¼‚æ­¥æ£€ç´¢å®ç°"""
        start_time = time.time()
        logger.info(f"å¼€å§‹å¼‚æ­¥æ–‡æ¡£æ£€ç´¢ - top_k: {top_k}, threshold: {similarity_threshold}")
        
        try:
            # æ¨¡æ‹Ÿå¼‚æ­¥å‘é‡æ£€ç´¢
            await asyncio.sleep(0.1)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿæ£€ç´¢ç»“æœ - å®é™…é¡¹ç›®ä¸­è¿æ¥çœŸå®å‘é‡æ•°æ®åº“
            mock_results = self._generate_mock_retrieval_results(query, top_k, similarity_threshold)
            
            retrieval_time = time.time() - start_time
            
            result = RetrievalResult(
                chunks=mock_results["chunks"],
                scores=mock_results["scores"],
                reranked_results=mock_results["chunks"],
                retrieval_time=retrieval_time
            )
            
            logger.info(f"å¼‚æ­¥æ£€ç´¢å®Œæˆ - ç”¨æ—¶: {retrieval_time:.3f}s, ç»“æœæ•°: {len(result.chunks)}")
            return result
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ£€ç´¢é”™è¯¯: {str(e)}")
            return RetrievalResult(
                chunks=[],
                scores=[],
                reranked_results=[],
                retrieval_time=0.0
            )
    
    async def _stream_retrieval_progress(self, query: str, top_k: int):
        """æµå¼æ£€ç´¢è¿›åº¦"""
        phases = [
            {"phase": "vector_search", "progress": 20},
            {"phase": "semantic_ranking", "progress": 40},
            {"phase": "threshold_filtering", "progress": 60},
            {"phase": "reranking", "progress": 80},
            {"phase": "candidate_selection", "progress": 100}
        ]
        
        for phase in phases:
            await asyncio.sleep(0.1)
            yield phase
    
    async def _async_intent_analysis(self, query: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ„å›¾åˆ†æ"""
        await asyncio.sleep(0.05)
        
        # ç®€å•çš„æ„å›¾åˆ†æ - å®é™…é¡¹ç›®ä¸­ä½¿ç”¨æ¨¡å‹åˆ†æ
        if any(word in query for word in ["å¦‚ä½•", "æ€æ ·", "æ€ä¹ˆ"]):
            intent = "how_to_instruction"
        elif any(word in query for word in ["ä»€ä¹ˆ", "å“ªä¸ª", "å®šä¹‰"]):
            intent = "definition_question"
        elif any(word in query for word in ["æ¯”è¾ƒ", "å¯¹æ¯”", "åŒºåˆ«"]):
            intent = "comparison_request"
        else:
            intent = "general_inquiry"
        
        # é¢†åŸŸè¯†åˆ«
        domain_keywords = {
            "technical": ["ç®—æ³•", "æ¶æ„", "ä»£ç ", "API"],
            "business": ["ä¼ä¸š", "å•†ä¸š", "ç›ˆåˆ©", "æˆæœ¬"],
            "development": ["å¼€å‘", "éƒ¨ç½²", "æµ‹è¯•", "CI/CD"]
        }
        
        detected_domains = []
        for domain, keywords in domain_keywords.items():
            if any(keyword in query for keyword in keywords):
                detected_domains.append(domain)
        
        return {
            "intent": intent,
            "domain": detected_domains[0] if detected_domains else "general",
            "complexity": "medium",
            "requires_mathematical": False,
            "requires_visual": False
        }
    
    async def _async_generate_answer(self, query: str, retrieval_result: RetrievalResult,
                                   intent_analysis: Dict[str, Any],
                                   temperature: float = 0.7,
                                   max_tokens: int = 1500) -> Dict[str, Any]:
        """å¼‚æ­¥ç”Ÿæˆç­”æ¡ˆ"""
        start_time = time.time()
        logger.info(f"å¼€å§‹å¼‚æ­¥ç­”æ¡ˆç”Ÿæˆ - intent: {intent_analysis['intent']}")
        
        try:
            # æ¨¡æ‹Ÿå¼‚æ­¥LLMè°ƒç”¨ - å®é™…é¡¹ç›®ä¸­è¿æ¥çœŸå®æ¨¡å‹API
            await asyncio.sleep(0.3)
            
            # åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆæ¨¡æ‹Ÿç­”æ¡ˆ
            if retrieval_result.chunks:
                base_answer = self._generate_answer_from_chunks(
                    query, retrieval_result.chunks, intent_analysis
                )
            else:
                base_answer = f"åŸºäºæ£€ç´¢ç»“æœï¼Œæˆ‘æ— æ³•æ‰¾åˆ°å…³äº '{query}' çš„å…·ä½“ä¿¡æ¯ã€‚"
            
            generation_time = time.time() - start_time
            
            # æ„å»ºå®Œæ•´å“åº”
            result = {
                "answer": base_answer,
                "sources": [
                    {
                        "document_id": f"doc_{i+1}",
                        "title": f"Enterprise Document {i+1}",
                        "content": chunk.get("content", "")[:200] + "...",
                        "score": retrieval_result.scores[i] if i < len(retrieval_result.scores) else 0.8,
                        "page": chunk.get("metadata", {}).get("page", 1)
                    }
                    for i, chunk in enumerate(retrieval_result.chunks[:3])
                ],
                "confidence": sum(retrieval_result.scores) / len(retrieval_result.scores) if retrieval_result.scores else 0.0,
                "generation_time": generation_time,
                "provider": "enterprise_async_llm",
                "metadata": {
                    "intent_analysis": intent_analysis,
                    "sources_count": len(retrieval_result.chunks),
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
            }
            
            logger.info(f"å¼‚æ­¥ç­”æ¡ˆç”Ÿæˆå®Œæˆ - ç”¨æ—¶: {generation_time:.3f}s")
            return result
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥ç­”æ¡ˆç”Ÿæˆé”™è¯¯: {str(e)}")
            return {
                "answer": "å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "sources": [],
                "confidence": 0.0,
                "generation_time": time.time() - start_time,
                "provider": "error_handler",
                "metadata": {"error": str(e)}
            }
    
    async def _stream_generate_answer(self, query: str, retrieval_result: RetrievalResult,
                                    intent_analysis: Dict[str, Any]) -> AsyncGenerator[Dict[str, str], None]:
        """æµå¼ç­”æ¡ˆç”Ÿæˆ"""
        
        answer_parts = [
            f"åŸºäºå¯¹ä¼ä¸šçŸ¥è¯†åº“çš„æ·±å…¥æ£€ç´¢ï¼Œæˆ‘æ¥å›ç­”æ‚¨å…³äº '{query}' çš„é—®é¢˜ï¼š\n\n",
            "é¦–å…ˆï¼Œæˆ‘ä»¬åˆ†ææ‚¨é—®é¢˜çš„æ ¸å¿ƒè¦ç´ ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äº",
            f"{intent_analysis['domain']}" if intent_analysis['domain'] == "technical" else "æŠ€æœ¯æ¶æ„",
            "çš„é—®é¢˜ã€‚\n\n",
            "é€šè¿‡å¯¹æ¯”ä¼ä¸šçº§æœ€ä½³å®è·µå’Œç›¸å…³æŠ€æœ¯æ–¹æ¡ˆï¼Œæˆ‘è®¤ä¸ºï¼š\n\n"
        ]
        
        yield {"text": answer_parts[0], "sequence": 0}
        await asyncio.sleep(0.2)
        
        yield {"text": answer_parts[1], "sequence": 1}
        await asyncio.sleep(0.15)
        
        yield {"text": answer_parts[2], "sequence": 2}
        await asyncio.sleep(0.1)
        
        yield {"text": answer_parts[3], "sequence": 3}
        await asyncio.sleep(0.2)
        
        # æ ¹æ®æ£€ç´¢ç»“æœç”Ÿæˆè¯¦ç»†å†…å®¹
        if retrieval_result.chunks:
            detailed_answer = f"åŸºäºæ£€ç´¢åˆ°çš„ {len(retrieval_result.chunks)} ä»½ç›¸å…³ä¼ä¸šæ–‡æ¡£ï¼Œ"
            contents = [chunk.get("content", "") for chunk in retrieval_result.chunks[:2]]
            detailed_answer += f"è¯¥é—®é¢˜çš„æœ€ä½³è§£å†³æ–¹æ¡ˆç»¼åˆäº†:\n\n1. {contents[0][:100]}...\n2. {contents[1][:100]}...\n"
            detailed_answer += f"æ­¤é¡¹æ–¹æ¡ˆåœ¨ä¼ä¸šç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰ {int(retrieval_result.scores[0] * 100)}% çš„ç›¸å…³æ€§è¯„åˆ†ã€‚\n\n"
            
            yield {"text": detailed_answer, "sequence": 4}
        
        final_statement = f"æ€»ç»“æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªä¼ä¸šä¸­å¸¸è§ä¸”å…·æœ‰æˆç†Ÿè§£å†³è·¯å¾„çš„é—®é¢˜ã€‚å»ºè®®æ‚¨å¯ä»¥è¿›ä¸€æ­¥" \
                         f"æ·±å…¥äº†è§£ç›¸å…³æŠ€æœ¯ç»†èŠ‚å¹¶è¿›è¡Œå®è·µéªŒè¯ã€‚\n\nå“åº”åŸºäºä¼ä¸šRAGç³»ç»Ÿï¼Œå…·æœ‰ {len(retrieval_result.chunks)} ä¸ªä¿¡æ¯æ¥æºã€‚"
        yield {"text": final_statement, "sequence": 5}
    
    def _generate_mock_retrieval_results(self, query: str, top_k: int, threshold: float) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ£€ç´¢ç»“æœ"""
        import random
        
        mock_documents = [
            {
                "document_id": f"doc_enterprise_{i+1}",
                "title": f"ä¼ä¸šçº§{query[:20]}æœ€ä½³å®è·µæŒ‡å—", 
                "content": f"è¿™ä»½ä¼ä¸šæ–‡æ¡£è¯¦ç»†æè¿°äº†å¦‚ä½•{query}ï¼Œæä¾›äº†å®Œæ•´çš„å®æ–½è·¯å¾„å’ŒæˆåŠŸæ¡ˆä¾‹ã€‚æ ¹æ®è¿‡å¾€é¡¹ç›®ç»éªŒï¼Œè¯¥æ–¹æ¡ˆå…·æœ‰é«˜åº¦çš„å¯å®æ–½æ€§å’Œè‰¯å¥½çš„ROIè¡¨ç°ã€‚",
                "metadata": {"source": f"Enterprise_Database_{i+1}", "page": random.randint(10, 50), "confidence": random.uniform(threshold, 1.0)}
            }
            for i in range(min(top_k, 5))
        ]
        
        scores = [doc["metadata"]["confidence"] for doc in mock_documents]
        
        return {
            "chunks": mock_documents,
            "scores": scores
        }
    
    def _generate_answer_from_chunks(self, query: str, chunks: List[Dict[str, Any]], intent_analysis: Dict[str, Any]) -> str:
        """ä»æ£€ç´¢å—ä¸­ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ"""
        answer = f"""
åŸºäºå¯¹ä¼ä¸šçº§çŸ¥è¯†åº“çš„æ£€ç´¢åˆ†æï¼Œå…³äº "{query}" çš„ä¸“ä¸šå›ç­”å¦‚ä¸‹ï¼š

é—®é¢˜åˆ†æï¼š
- æŸ¥è¯¢ç±»å‹ï¼š{intent_analysis['intent']}
- é¢†åŸŸåˆ†ç±»ï¼š{intent_analysis['domain']}
- å¤æ‚åº¦ï¼š{intent_analysis['complexity']}

ç»¼åˆè§£å†³æ–¹æ¡ˆï¼š
"""

        # åŸºäºæ£€ç´¢å†…å®¹æ„å»ºå›ç­”ä¸»ä½“
        if chunks:
            answer += f"æ£€ç´¢åˆ° {len(chunks)} ä¸ªç›¸å…³ä¿¡æ¯æºï¼Œä¸»è¦è¦ç‚¹åŒ…æ‹¬ï¼š\n\n"
            
            for i, chunk in enumerate(chunks[:3]):  # ä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„ç»“æœ
                content = chunk.get("content", "")
                title = chunk.get("title", f"ä¿¡æ¯æº {i+1}")
                score = chunk.get("metadata", {}).get("confidence", 0.8)
                
                answer += f"{i+1}. **{title}** (ç›¸å…³æ€§: {score:.1%})\n"
                answer += f"   {content[:150]}...\n\n"
        
        answer += """
å®æ–½å»ºè®®ï¼š
ç»“åˆä¼ä¸šçº§æœ€ä½³å®è·µå’Œæ£€ç´¢å¾—åˆ°çš„ä¸“ä¸šçŸ¥è¯†ï¼Œå»ºè®®æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œå®è·µï¼š

1. ç»†åŒ–éœ€æ±‚åˆ†æå’Œåœºæ™¯é€‚é…
2. è®¾è®¡å®Œæ•´çš„æŠ€æœ¯å®æ–½è®¡åˆ’  
3. å»ºç«‹å®Œå–„çš„æ•ˆæœè¯„ä¼°æœºåˆ¶
4. é…ç½®ç›‘æ§å‘Šè­¦å’Œåç»­ä¼˜åŒ–

è¯¥æ–¹æ¡ˆå·²åœ¨å¤šä¸ªçœŸå®ä¼ä¸šç¯å¢ƒä¸­æˆåŠŸå®æ–½ï¼Œå…·æœ‰å¯é çš„æŠ€æœ¯åŸºç¡€å’Œbusiness valueã€‚é¼“åŠ±è¿›ä¸€æ­¥æ·±å…¥ç ”ç©¶å’Œå®è·µéªŒè¯ã€‚"""
        
        return answer
    
    async def _log_query_async(self, query_data: RAGQuery, response: RAGResponse) -> None:
        """å¼‚æ­¥è®°å½•æŸ¥è¯¢æ—¥å¿—"""
        log_entry = {
            "request_id": response.request_id,
            "query": query_data.query,
            "domain": query_data.domain,
            "response_time": response.processing_time,
            "confidence": response.confidence,
            "sources_count": len(response.sources),
            "timestamp": response.timestamp.isoformat()
        }
        
        self.query_history.append(log_entry)
        logger.info(f"å¼‚æ­¥è®°å½•æŸ¥è¯¢æ—¥å¿— - RID: {response.request_id}")
    
    async def _log_stream_query_async(self, query_data: RAGQuery, final_answer: str, 
                                     total_time: float, request_id: str) -> None:
        """å¼‚æ­¥è®°å½•æµå¼æŸ¥è¯¢æ—¥å¿—"""
        log_entry = {
            "request_id": request_id,
            "query": query_data.query,
            "type": "stream",
            "answer_length": len(final_answer),
            "total_time": total_time,
            "timestamp": datetime.now().isoformat()
        }
        
        self.query_history.append(log_entry)
        logger.info(f"å¼‚æ­¥è®°å½•æµå¼æŸ¥è¯¢ - RID: {request_id}, ç”¨æ—¶: {total_time:.3f}s")
    
    async def _update_performance_stats(self, response_time: float) -> None:
        """å¼‚æ­¥æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats["total_queries"] += 1
        
        total_queries = self.performance_stats["total_queries"] 
        current_avg = self.performance_stats["avg_response_time"]
        
        # ç§»åŠ¨å¹³å‡è®¡ç®—
        self.performance_stats["avg_response_time"] = (
            (current_avg * (total_queries - 1) + response_time) / total_queries
        )
        
        logger.info(f"æ€§èƒ½ç»Ÿè®¡æ›´æ–° - æ€»æŸ¥è¯¢: {total_queries}, å¹³å‡å“åº”: {self.performance_stats['avg_response_time']:.3f}s")
    
    def _handle_timeout_error(self, query: str, request_id: str) -> RAGResponse:
        """å¤„ç†è¶…æ—¶é”™è¯¯"""
        return RAGResponse(
            query=query,
            answer="æŠ±æ­‰ï¼ŒæŸ¥è¯¢å¤„ç†è¶…æ—¶ã€‚è¿™å¯èƒ½æ˜¯ç”±äºç³»ç»Ÿè´Ÿè½½è¾ƒé«˜æˆ–æ£€ç´¢æ–‡æ¡£è¿‡å¤šå¯¼è‡´çš„ã€‚è¯·ç¨åé‡è¯•æˆ–ç®€åŒ–æ‚¨çš„æŸ¥è¯¢ã€‚",
            sources=[],
            confidence=0.0,
            processing_time=self.config.query_timeout_seconds,
            request_id=request_id,
            timestamp=datetime.now(),
            metadata={"error": "query_timeout", "timeout_seconds": self.config.query_timeout_seconds}
        )
    
    async def _handle_processing_error(self, query: str, error_message: str, request_id: str) -> RAGResponse:
        """å¤„ç†å¤„ç†é”™è¯¯"""
        logger.error(f"æŸ¥è¯¢å¤„ç†é”™è¯¯ - RID: {request_id}, é”™è¯¯: {error_message}")
        
        return RAGResponse(
            query=query,
            answer="æŸ¥è¯¢å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯ã€‚è¯·ç¨åé‡è¯•ï¼Œå¦‚é—®é¢˜æŒç»­è¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚",
            sources=[],
            confidence=0.0,
            processing_time=0.0,
            request_id=request_id,
            timestamp=datetime.now(),
            metadata={"error": error_message}
        )
    
    async def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        active_queries = len([req async for req in self._get_active_requests()])
        cache_hit_rate = await self._calculate_cache_hit_rate()
        
        return {
            "runtime_statistics": {
                "total_queries_processed": self.performance_stats["total_queries"],
                "average_response_time": round(self.performance_stats["avg_response_time"], 3),
                "cache_hit_rate": round(cache_hit_rate, 2),
                "active_concurrent_requests": active_queries
            },
            "capacity_metrics": {
                "max_concurrent_queries": self.config.max_concurrent_queries,
                "current_semaphore_value": self.request_semaphore._value,
                "memory_usage": self._get_memory_usage()
            },
            "recent_queries": self.query_history[-10:] if len(self.query_history) >= 10 else self.query_history,
            "system_timestamp": datetime.now().isoformat()
        }
    
    async def _get_active_requests(self):
        """è·å–æ´»è·ƒè¯·æ±‚ï¼ˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼‰"""
        if hasattr(self.request_semaphore, '_waiters'):
            for waiter in self.request_semaphore._waiters:
                yield waiter
    
    async def _calculate_cache_hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        # ç®€åŒ–å®ç°
        return 0.85  # æ¨¡æ‹Ÿ85%ç¼“å­˜å‘½ä¸­ç‡
    
    def _get_memory_usage(self) -> Dict[str, int]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        import psutil
        try:
            process = psutil.Process()
            return {"rss_mb": int(process.memory_info().rss / 1024 / 1024)}
        except:
            return {"rss_mb": 0}

# FastAPIåº”ç”¨æ„å»ºå™¨
class AsyncRAGServiceAPIBuilder:
    """å¼‚æ­¥RAGæœåŠ¡APIæ„å»ºå™¨"""
    
    def __init__(self):
        self.rag_service = EnterpriseAsyncRAGService()
        self.app = None
    
    def create_async_rag_service_api(self) -> FastAPI:
        """åˆ›å»ºå¼‚æ­¥RAGæœåŠ¡API"""
        logger.info("ğŸš€ æ„å»ºå¼‚æ­¥RAGæœåŠ¡APIåº”ç”¨")
        
        app = FastAPI(
            title="ğŸŒŸ ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡API",
            description="""
ä¼ä¸šçº§LangChainå¼‚æ­¥RAGå¤„ç†æœåŠ¡

âœ¨ **æ ¸å¿ƒç‰¹æ€§:**
- å¼‚æ­¥é«˜å¹¶å‘å¤„ç† (Async/await optimization)
- Server-Sent Eventsæµå¼å“åº”æ”¯æŒ
- æ™ºèƒ½æ£€ç´¢ä¸é‡æ’åºç®—æ³•
- Redisç¼“å­˜é›†æˆä¸ä¼˜åŒ–
- Qdrantå‘é‡æ•°æ®åº“æ”¯æŒ
- å®æ—¶æ€§èƒ½ç›‘æ§ä¸ç»Ÿè®¡

ğŸ­ **ä¼ä¸šçº§ç‰¹æ€§:**
- ä¸Šä¸‹æ–‡å…³è”æ£€ç´¢
- å¤šæ¨¡æ€RAGå¤„ç†
- æµå¼å“åº”ä½“éªŒ
- å¯æ‰©å±•æ¶æ„è®¾è®¡
- ç”Ÿäº§çº§é”™è¯¯å¤„ç†
""",
            version="1.0.0",
            docs_url="/docs",
            redoc_url="/redoc"
        )

        # æ·»åŠ å¼‚æ­¥ä¸­é—´ä»¶
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        self._setup_async_routes(app)
        self.app = app
        return app
    
    def _setup_async_routes(self, app: FastAPI):
        """è®¾ç½®å¼‚æ­¥è·¯ç”±"""
        
        # å¥åº·æ£€æŸ¥
        @app.get("/api/v2/health")
        async def health_check():
            """å¼‚æ­¥å¥åº·æ£€æŸ¥"""
            stats = await self.rag_service.get_system_stats()
            return {"status": "healthy", "stats": stats}
        
        # å¼‚æ­¥RAGæŸ¥è¯¢
        @app.post("/api/v2/rag/async-query")
        async def async_rag_query(query_data: dict):
            """æ ‡å‡†å¼‚æ­¥RAGæŸ¥è¯¢"""
            try:
                rag_query = RAGQuery(**query_data)
                response = await self.rag_service.process_query_async(rag_query)
                return {
                    "success": True,
                    "request_id": response.request_id,
                    "data": response.__dict__,
                    "processing_time": response.processing_time
                }
            except Exception as e:
                logger.error(f"å¼‚æ­¥æŸ¥è¯¢é”™è¯¯: {str(e)}")
                return {
                    "success": False,
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
        
        # Server-Sent Eventsæµå¼æŸ¥è¯¢
        @app.post("/api/v2/rag/stream-query")
        async def stream_rag_query(query_data: dict):
            """æµå¼RAGæŸ¥è¯¢ï¼ˆServer-Sent Eventsï¼‰"""
            try:
                rag_query = RAGQuery(**query_data)
                return StreamingResponse(
                    self.rag_service.stream_query_async(rag_query),
                    media_type="text/event-stream",
                    headers={
                        "Cache-Control": "no-cache",
                        "Connection": "keep-alive",
                        "X-Accel-Buffering": "no"
                    }
                )
            except Exception as e:
                logger.error(f"æµå¼æŸ¥è¯¢é”™è¯¯: {str(e)}")
                return JSONResponse(
                    status_code=500,
                    content={
                        "success": False,
                        "error": str(e),
                        "timestamp": datetime.now().isoformat()
                    }
                )
        
        # æ‰¹é‡å¼‚æ­¥æŸ¥è¯¢
        @app.post("/api/v2/rag/batch-query")
        async def batch_rag_query(batch_data: dict):
            """æ‰¹é‡å¼‚æ­¥RAGæŸ¥è¯¢"""
            try:
                queries = batch_data.get("queries", [])
                concurrent_limit = batch_data.get("max_concurrent", 5)
                
                if len(queries) > 20:
                    return {"success": False, "error": "æ‰¹é‡æŸ¥è¯¢æœ€å¤šæ”¯æŒ20æ¡"}
                
                # ä½¿ç”¨Semaphoreæ§åˆ¶å¹¶å‘
                semaphore = asyncio.Semaphore(concurrent_limit)
                
                async def query_with_semaphore(query_data):
                    async with semaphore:
                        rag_query = RAGQuery(**query_data)
                        response = await self.rag_service.process_query_async(rag_query)
                        return {
                            "query": query_data.get("query"), 
                            "request_id": response.request_id,
                            "response_time": response.processing_time
                        }
                
                # æ‰¹é‡å¼‚æ­¥æ‰§è¡Œ
                batch_start = time.time()
                results = await asyncio.gather(
                    *[query_with_semaphore(q) for q in queries],
                    return_exceptions=True
                )
                
                batch_time = time.time() - batch_start
                
                return {
                    "success": True,
                    "batch_results": results,
                    "total_batch_time": batch_time,
                    "average_response_time": batch_time / len(queries) if queries else 0
                }
            except Exception as e:
                return {"success": False, "error": str(e)}

def main():
    """ä¸»å‡½æ•°ï¼šæµ‹è¯•å¼‚æ­¥RAGæœåŠ¡"""
    print("ğŸŒŸ LangChain L3 Advanced - Week 11: ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡")
    print("=" * 70)
    
    builder = AsyncRAGServiceAPIBuilder()
    
    try:
        # åˆ›å»ºå¼‚æ­¥RAGæœåŠ¡API
        app = builder.create_async_rag_service_api()
        
        print("\nâœ… ä¼ä¸šçº§å¼‚æ­¥RAGæœåŠ¡APIåˆ›å»ºæˆåŠŸï¼")
        print("\nğŸ“‘ ä¸»è¦ç‰¹æ€§ï¼š")
        print("   ğŸŒŠ å¼‚æ­¥å¹¶å‘æŸ¥è¯¢å¤„ç†")
        print("   ğŸ“¡ Server-Sent Eventsæµå¼å“åº”")
        print("   ğŸ’¨ Rediså¼‚æ­¥ç¼“å­˜é›†æˆ")
        print("   ğŸ¯ Qdrantå‘é‡æ•°æ®åº“æ”¯æŒ")
        print("   ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§")
        print("   ğŸ”§ æ‰¹é‡å¹¶å‘æŸ¥è¯¢")
        
        print("\nğŸš€ æµ‹è¯•APIç«¯ç‚¹ï¼š")
        print("   POST /api/v2/rag/async-query     - æ ‡å‡†å¼‚æ­¥æŸ¥è¯¢")
        print("   POST /api/v2/rag/stream-query    - æµå¼æŸ¥è¯¢(SSE)")
        print("   POST /api/v2/rag/batch-query     - æ‰¹é‡æŸ¥è¯¢")
        print("   GET  /api/v2/health              - ç³»ç»Ÿå¥åº·æ£€æŸ¥")
        
        print("\nğŸŒ å¯åŠ¨åº”ç”¨ï¼š")
        print("   python 02_async_rag_service.py")
        
        import uvicorn
        
        # å¦‚æœç›´æ¥è¿è¡Œï¼Œå¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(app, host="0.0.0.0", port=8001, log_level="info")
        
    except Exception as e:
        print(f"\nâŒ å¼‚æ­¥RAGæœåŠ¡åˆ›å»ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()