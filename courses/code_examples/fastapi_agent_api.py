#!/usr/bin/env python3
"""
LangChain 1.0 é«˜é˜¶ç¤ºä¾‹: FastAPI + Agent ä¼ä¸šçº§åº”ç”¨
è¯¾ç¨‹åç§°: L3 Advanced - ä¼ä¸šçº§æ™ºèƒ½ä½“API
"""

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.responses import StreamingResponse
from fastapi.security import APIKeyHeader
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, AsyncGenerator
import asyncio
import json
from datetime import datetime
import logging
from uuid import uuid4
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸš€ FastAPI åº”ç”¨åˆå§‹åŒ–
app = FastAPI(
    title="LangChainä¸­å›½æ™ºèƒ½ä½“API",
    description="ä¼ä¸šçº§LangChain 1.0æ™ºèƒ½ä½“åº”ç”¨å¹³å°",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# ğŸ”‘ APIå®‰å…¨é…ç½®
API_KEY_HEADER = APIKeyHeader(name="X-API-Key")
API_KEYS = {
    "demo_key_001": {"user": "demo_user", "rate_limit": 100},
    "ent_key_002": {"user": "enterprise_user", "rate_limit": 1000}
}

# ğŸ’¾ å…¨å±€çŠ¶æ€ç®¡ç†
class GlobalState:
    def __init__(self):
        self.active_sessions: Dict[str, dict] = {}
        self.session_history: Dict[str, List] = {}
        self.performance_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "avg_response_time": 0
        }

app_state = GlobalState()

# ğŸ“‹ Pydanticæ•°æ®æ¨¡å‹
class ChatRequest(BaseModel):
    message: str = Field(..., description="ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯", min_length=1, max_length=1000)
    session_id: Optional[str] = Field(None, description="ä¼šè¯IDï¼Œç”¨äºç»´æŒä¸Šä¸‹æ–‡")
    context: Optional[dict] = Field(None, description="é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯")
    model_name: str = Field("glm-4", description="ä½¿ç”¨çš„æ¨¡å‹åç§°")
    temperature: float = Field(0.7, description="æ¨¡å‹æ¸©åº¦å‚æ•°", ge=0.0, le=2.0)
    max_tokens: int = Field(1000, description="æœ€å¤§è¾“å‡ºtokenæ•°", ge=1, le=4096)

class ChatResponse(BaseModel):
    success: bool
    data: dict
    session_id: str
    timestamp: datetime
    metadata: dict

class AgentSession(BaseModel):
    session_id: str
    user_id: str
    created_at: datetime
    last_activity: datetime
    status: str
    context: dict

class PerformanceMetrics(BaseModel):
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    active_sessions: int

# ğŸ” éªŒè¯å‡½æ•°
def verify_api_key(api_key: str = Depends(API_KEY_HEADER)):
    """éªŒè¯APIå¯†é’¥"""
    if api_key not in API_KEYS:
        raise HTTPException(status_code=401, detail="Invalid API Key")
    return API_KEYS[api_key]

# ğŸ§ æ™ºèƒ½ä½“æ ¸å¿ƒç±»
class EnterpriseAgent:
    """ä¼ä¸šçº§æ™ºèƒ½ä½“æ ¸å¿ƒç±»"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.capabilities = [
            "ä¸­æ–‡é—®ç­”", "æ•°æ®åˆ†æ", "ä»£ç ç”Ÿæˆ", 
            "æ–‡æ¡£æ€»ç»“", "ç¿»è¯‘æœåŠ¡", "å•†ä¸šå»ºè®®"
        ]
        self.memory = {}
        self.session_context = {}
    
    async def process_message(self, message: str, context: dict) -> dict:
        """å¤„ç†è¾“å…¥æ¶ˆæ¯"""
        
        # æ¨¡æ‹Ÿæ™ºèƒ½å¤„ç†é€»è¾‘
        if "è®¡ç®—" in message or "math" in message.lower():
            return {
                "type": "calculation",
                "content": await self._handle_calculation(message),
                "tools_used": ["æ•°å­¦è®¡ç®—å™¨"]
            }
        elif "ç¿»è¯‘" in message or "translate" in message.lower():
            return {
                "type": "translation", 
                "content": await self._handle_translation(message),
                "tools_used": ["ç¿»è¯‘æœåŠ¡"]
            }
        elif "ä»£ç " in message or "code" in message.lower():
            return {
                "type": "code_generation",
                "content": await self._handle_code_generation(message),
                "tools_used": ["ä»£ç ç”Ÿæˆå™¨"]
            }
        else:
            return {
                "type": "general_chat",
                "content": await self._handle_general_chat(message),
                "tools_used": ["å¯¹è¯å¼•æ“"]
            }
    
    async def _handle_calculation(self, message: str) -> str:
        """å¤„ç†æ•°å­¦è®¡ç®—"""
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        return f"ğŸ“Š æ•°å­¦è®¡ç®—ç»“æœ: å·²å¤„ç†å¤æ‚è®¡ç®—é€»è¾‘ï¼Œå…·ä½“ç»“æœ={hash(message) % 100}"
    
    async def _handle_translation(self, message: str) -> str:
        """å¤„ç†ç¿»è¯‘è¯·æ±‚"""
        await asyncio.sleep(0.2)
        return "ğŸŒ ç¿»è¯‘æœåŠ¡: è‹±æ–‡ç¿»è¯‘ - > 'This is a sample translation'"
    
    async def _handle_code_generation(self, message: str) -> str:
        """å¤„ç†ä»£ç ç”Ÿæˆ"""
        await asyncio.sleep(0.3)
        code_sample = """
def hello_world():
    print("Hello, LangChain Enterprise!")
    return {"status": "success", "message": "Generated by Enterprise Agent"}
        """
        return f"ğŸ§‘â€ğŸ’» ä»£ç ç”Ÿæˆå®Œæˆ:\n```python\n{code_sample}\n```"
    
    async def _handle_general_chat(self, message: str) -> str:
        """å¤„ç†é€šç”¨å¯¹è¯"""
        await asyncio.sleep(0.1)
        return f"ğŸ¤– ä¼ä¸šæ™ºèƒ½ä½“å›åº”: æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ '{message}'ã€‚æˆ‘æ˜¯æ‚¨çš„ä¸“å±æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦å“ªæ–¹é¢çš„å¸®åŠ©ã€‚"
    
    def get_capability_summary(self) -> dict:
        """è·å–èƒ½åŠ›æ‘˜è¦"""
        return {
            "agent_id": self.agent_id,
            "capabilities": self.capabilities,
            "status": "active",
            "memory_size": len(self.memory)
        }

# ğŸŒ FastAPIç«¯ç‚¹å®ç°

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("LangChainä¼ä¸šçº§æ™ºèƒ½ä½“APIæœåŠ¡å¯åŠ¨")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    logger.info("LangChainä¼ä¸šçº§æ™ºèƒ½ä½“APIæœåŠ¡å…³é—­")

# ğŸ  åŸºç¡€ç«¯ç‚¹
@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "message": "æ¬¢è¿ä½¿ç”¨LangChainä¸­å›½æ™ºèƒ½ä½“API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health", response_model=dict)
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "service": "LangChain Enterprise Agent API",
        "uptime": time.time()  # ç®€åŒ–ç‰ˆæ­£å¸¸è¿è¡Œæ—¶é—´
    }

# ğŸ§  æ™ºèƒ½ä½“ç®¡ç†ç«¯ç‚¹
@app.post("/agent/create", response_model=AgentSession)
async def create_agent_session(
    background_tasks: BackgroundTasks,
    user_role: dict = Depends(verify_api_key)
):
    """åˆ›å»ºæ–°çš„æ™ºèƒ½ä½“ä¼šè¯"""
    session_id = str(uuid4())
    agent = EnterpriseAgent(session_id)
    
    app_state.active_sessions[session_id] = {
        "agent": agent,
        "created_at": datetime.now(),
        "user": user_role["user"]
    }
    
    background_tasks.add_task(log_session_creation, session_id, user_role["user"])
    
    return AgentSession(
        session_id=session_id,
        user_id=user_role["user"],
        created_at=datetime.now(),
        last_activity=datetime.now(),
        status="active",
        context={}
    )

# ğŸ’¬ æ ¸å¿ƒèŠå¤©ç«¯ç‚¹
@app.post("/chat/message", response_model=ChatResponse)
async def process_chat_message(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    user_role: dict = Depends(verify_api_key)
):
    """å¤„ç†èŠå¤©æ¶ˆæ¯ - æ ¸å¿ƒç«¯ç‚¹"""
    
    start_time = time.time()
    session_id = request.session_id or str(uuid4())
    
    try:
        # è·å–æˆ–åˆ›å»ºæ™ºèƒ½ä½“session
        if session_id in app_state.active_sessions:
            agent = app_state.active_sessions[session_id]["agent"]
        else:
            agent = EnterpriseAgent(session_id)
            app_state.active_sessions[session_id] = {
                "agent": agent,
                "created_at": datetime.now(),
                "user": user_role["user"]
            }
        
        # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†æ¶ˆæ¯
        agent_response = await agent.process_message(
            message=request.message,
            context=request.context or {}
        )
        
        # æ„å»ºå“åº”
        response_data = {
            "user_message": request.message,
            "agent_response": agent_response["content"],
            "processing_type": agent_response["type"],
            "tools_used": agent_response["tools_used"],
            "response_time": time.time() - start_time
        }
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        app_state.performance_metrics["total_requests"] += 1
        app_state.performance_metrics["successful_requests"] += 1
        
        background_tasks.add_task(
            log_chat_interaction, 
            session_id, request.message, response_data
        )
        
        return ChatResponse(
            success=True,
            data=response_data,
            session_id=session_id,
            timestamp=datetime.now(),
            metadata={
                "model_used": request.model_name,
                "response_time": time.time() - start_time
            }
        )
        
    except Exception as e:
        logger.error(f"Error processing chat message: {str(e)}")
        app_state.performance_metrics["failed_requests"] += 1
        
        raise HTTPException(
            status_code=500, 
            detail=f"Intelligent processing failed: {str(e)}"
        )

# ğŸ“Š æµå¼å“åº”ç«¯ç‚¹
@app.post("/chat/stream")
async def process_chat_stream(
    request: ChatRequest,
    user_role: dict = Depends(verify_api_key)
):
    """æµå¼å¤„ç†èŠå¤©æ¶ˆæ¯"""
    
    async def generate_stream() -> AsyncGenerator[str, None]:
        """ç”Ÿæˆæµå¼å“åº”"""
        # åˆ†æ®µé€æ­¥è¾“å‡º
        response_chunks = [
            f"data: {json.dumps({'status': 'initialized', 'session_id': str(uuid4())})}\n\n",
            f"data: {json.dumps({'status': 'processing', 'message': 'æ­£åœ¨åˆ†æä¸­...'})}\n\n",
            f"data: {json.dumps({'status': 'thinking', 'message': 'æ€è€ƒè§£å†³æ–¹æ¡ˆä¸­...'})}\n\n",
            f"data: {json.dumps({'status': 'responding', 'content': 'è¿™æ˜¯æµå¼å“åº”çš„ç¬¬ä¸€éƒ¨åˆ†'})}\n\n",
            f"data: {json.dumps({'status': 'responding', 'content': 'è¿™æ˜¯æµå¼å“åº”çš„ç¬¬äºŒéƒ¨åˆ†'})}\n\n",
            f"data: {json.dumps({'status': 'completed', 'content': 'æµå¼å“åº”å®Œæˆï¼'})}\n\n",
            "data: [DONE]\n\n"
        ]
        
        for chunk in response_chunks:
            yield chunk
            await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

# ğŸ“ˆ ç³»ç»Ÿç›‘æ§ç«¯ç‚¹  
@app.get("/metrics", response_model=PerformanceMetrics)
async def get_performance_metrics(
    user_role: dict = Depends(verify_api_key)
):
    """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    
    metrics = PerformanceMetrics(
        total_requests=app_state.performance_metrics["total_requests"],
        successful_requests=app_state.performance_metrics["successful_requests"],
        failed_requests=app_state.performance_metrics["failed_requests"],
        avg_response_time=app_state.performance_metrics["avg_response_time"],
        active_sessions=len(app_state.active_sessions)
    )
    
    return metrics

# ğŸ§° æ”¯æŒåŠŸèƒ½
async def log_session_creation(session_id: str, user: str):
    """è®°å½•ä¼šè¯åˆ›å»ºæ—¥å¿—"""
    logger.info(f"Session created - ID: {session_id}, User: {user}")

async def log_chat_interaction(session_id: str, user_message: str, response_data: dict):
    """è®°å½•èŠå¤©äº¤äº’æ—¥å¿—"""
    logger.info(f"Chat interaction - Session: {session_id}, Response time: {response_data.get('response_time', 'unknown')}")

# ğŸš€ å¯åŠ¨é…ç½®
if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "fastapi_agent_api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )

print("\nğŸš€ ä¼ä¸šçº§æ™ºèƒ½ä½“APIå·²å¯åŠ¨")
print("Swaggeræ–‡æ¡£: http://localhost:8000/docs")
print("ReDocæ–‡æ¡£: http://localhost:8000/redoc")
print("å¥åº·æ£€æŸ¥: http://localhost:8000/health")